{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b4d7b3-30d8-43aa-afda-b000e1913017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import tag\n",
    "from nltk import chunk\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a68ce9e1-69c6-47bf-b5a0-366b24193acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb5947f-fa2c-4240-885e-5fc2d0105a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello my name is xyz from xyx college\"\n",
    "data = tokenize.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "580e0205-94e9-47ed-9b8f-0a5ad1c55f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'my', 'name', 'is', 'xyz', 'from', 'xyx', 'college']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    words= tokenize.word_tokenize(data[i])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6ccb83f-877c-4e6c-9813-85e2326ef514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Hello', 'NNP'), ('my', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('xyz', 'VBN'), ('from', 'IN'), ('xyx', 'NNP'), ('college', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "tagged_words=[]\n",
    "for i in range(len(data)):\n",
    "    tagged_words.append(tag.pos_tag(words))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33be92d6-64d1-4c4e-9746-e6d032c8654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [('Hello', 'NNP'), ('my', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('xyz', 'VBN'), ('from', 'IN'), ('xyx', 'NNP'), ('college', 'NN')])]\n"
     ]
    }
   ],
   "source": [
    "chunkk=[]\n",
    "for i in range(len(data)):\n",
    "    chunkk.append(chunk.ne_chunk(tagged_words[i]))\n",
    "print(chunkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0322e-a6b6-4ec5-b41b-9278271e37b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
